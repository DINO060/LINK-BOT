# -*- coding: utf-8 -*-
import re
import urllib.parse
from typing import Optional, Dict
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import requests

def _normalize_site(site_or_url: str) -> str:
    """Normalise l'URL du site"""
    if site_or_url.startswith("http"):
        return site_or_url
    return f"https://{site_or_url.strip('/')}"

def _is_sibnet(iframe_url: str) -> bool:
    """V√©rifie si l'URL est un iframe Sibnet"""
    return iframe_url and "sibnet" in iframe_url.lower()

def _to_sibnet_share(iframe_url: str) -> str:
    """Convertit une iframe Sibnet en lien de partage"""
    if not _is_sibnet(iframe_url):
        return iframe_url
    
    # shell.php?videoid=123 ‚Üí https://video.sibnet.ru/video123
    m = re.search(r"(?:shell|frame)\.php\?videoid=(\d+)", iframe_url, flags=re.I)
    if m:
        return f"https://video.sibnet.ru/video{m.group(1)}"
    
    # D√©j√† un lien video.sibnet.ru
    if "video.sibnet.ru" in iframe_url:
        return iframe_url
    
    return iframe_url

def ddg_first_result_site(domain: str, keyword: str) -> Optional[str]:
    """Fallback DuckDuckGo pour trouver la page de l'anime"""
    from .fast_jump import ddg_first_site
    return ddg_first_site(domain, keyword)

async def _type_search_or_fallback(page, start_url: str, keyword: str, timeout_ms: int) -> bool:
    """Effectue une recherche sur le site"""
    try:
        # Chercher un champ de recherche
        search_input = page.locator("input[type='search'], input[name*='search'], input[name*='q'], #search")
        
        if await search_input.count() > 0:
            print(f"üîç Recherche interne: {keyword}")
            await search_input.first.fill(keyword)
            await search_input.first.press("Enter")
            await page.wait_for_load_state("domcontentloaded", timeout=timeout_ms)
            return True
        else:
            print("‚ö†Ô∏è Pas de champ de recherche trouv√©")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur recherche interne: {e}")
        return False

async def _pick_first_result(page, timeout_ms: int) -> Optional[str]:
    """S√©lectionne le premier r√©sultat de recherche"""
    try:
        # S√©lecteurs communs pour les r√©sultats de recherche
        selectors = [
            "a[href*='catalogue']",  # anime-sama.fr sp√©cifique
            ".search-result a", 
            ".result a",
            "article a",
            ".post a",
            ".entry a"
        ]
        
        for selector in selectors:
            links = page.locator(selector)
            if await links.count() > 0:
                first_link = await links.first.get_attribute("href")
                if first_link:
                    # Convertir en URL absolue si n√©cessaire
                    if first_link.startswith("/"):
                        base_url = urllib.parse.urljoin(page.url, "/")
                        first_link = urllib.parse.urljoin(base_url, first_link)
                    print(f"‚úÖ Premier r√©sultat: {first_link}")
                    return first_link
        
        print("‚ùå Aucun r√©sultat trouv√©")
        return None
        
    except Exception as e:
        print(f"‚ùå Erreur s√©lection r√©sultat: {e}")
        return None

async def _episode_dropdown_locators(page):
    """Trouve les s√©lecteurs d'√©pisodes et de lecteurs"""
    try:
        # S√©lecteurs typiques pour anime-sama.fr
        ep_selectors = [
            "select[name*='episode']",
            "#episode-select", 
            ".episode-select",
            "select option[value*='episode']"
        ]
        
        lecteur_selectors = [
            "select[name*='player']",
            "#player-select",
            ".player-select", 
            "select option[value*='lecteur']"
        ]
        
        ep_sel = None
        for selector in ep_selectors:
            if await page.locator(selector).count() > 0:
                ep_sel = selector
                break
        
        lecteur_sel = None
        for selector in lecteur_selectors:
            if await page.locator(selector).count() > 0:
                lecteur_sel = selector
                break
        
        print(f"üì∫ Episode selector: {ep_sel}")
        print(f"üé¨ Player selector: {lecteur_sel}")
        
        return ep_sel, lecteur_sel
        
    except Exception as e:
        print(f"‚ùå Erreur localisation dropdowns: {e}")
        return None, None

async def _select_episode(page, ep_selector: Optional[str], episode: Optional[int]) -> str:
    """S√©lectionne un √©pisode sp√©cifique"""
    if not ep_selector or not episode:
        return "(aucun √©pisode s√©lectionn√©)"
    
    try:
        # Chercher l'option avec le num√©ro d'√©pisode
        options = page.locator(f"{ep_selector} option")
        count = await options.count()
        
        for i in range(count):
            option = options.nth(i)
            text = await option.text_content()
            value = await option.get_attribute("value")
            
            # Chercher le num√©ro d'√©pisode dans le texte ou la valeur
            if str(episode) in text or str(episode) in (value or ""):
                await option.click()
                await page.wait_for_timeout(1000)  # Attendre le chargement
                print(f"‚úÖ √âpisode s√©lectionn√©: {text}")
                return text.strip()
        
        print(f"‚ö†Ô∏è √âpisode {episode} non trouv√©")
        return f"(√©pisode {episode} non trouv√©)"
        
    except Exception as e:
        print(f"‚ùå Erreur s√©lection √©pisode: {e}")
        return "(erreur s√©lection √©pisode)"

async def _try_each_player_until_sibnet(page, lecteur_selector: Optional[str]):
    """Teste chaque lecteur jusqu'√† trouver Sibnet"""
    if not lecteur_selector:
        # Pas de s√©lecteur de lecteur, chercher directement les iframes
        return await _extract_iframe_from_page(page)
    
    try:
        options = page.locator(f"{lecteur_selector} option")
        count = await options.count()
        
        for i in range(count):
            option = options.nth(i)
            text = await option.text_content()
            
            # S√©lectionner ce lecteur
            await option.click()
            await page.wait_for_timeout(2000)  # Attendre le chargement
            
            # Extraire l'iframe
            iframe_url = await _extract_iframe_from_page(page)
            
            if _is_sibnet(iframe_url):
                print(f"üéØ Sibnet trouv√© avec lecteur: {text}")
                return text.strip(), iframe_url
        
        # Si aucun Sibnet trouv√©, retourner le premier lecteur
        if count > 0:
            first_option = options.first
            await first_option.click()
            await page.wait_for_timeout(2000)
            iframe_url = await _extract_iframe_from_page(page)
            text = await first_option.text_content()
            print(f"‚ö†Ô∏è Sibnet non trouv√©, utilisation du premier lecteur: {text}")
            return text.strip(), iframe_url
        
        return "(aucun lecteur)", ""
        
    except Exception as e:
        print(f"‚ùå Erreur test lecteurs: {e}")
        return "(erreur lecteurs)", ""

async def _extract_iframe_from_page(page) -> str:
    """Extrait l'URL de l'iframe principal"""
    try:
        # Chercher les iframes
        iframes = page.locator("iframe")
        count = await iframes.count()
        
        for i in range(count):
            iframe = iframes.nth(i)
            src = await iframe.get_attribute("src")
            
            if src and ("sibnet" in src.lower() or "video" in src.lower()):
                print(f"üìπ Iframe trouv√©e: {src}")
                return src
        
        # Si pas d'iframe sp√©cifique, prendre la premi√®re
        if count > 0:
            first_src = await iframes.first.get_attribute("src")
            if first_src:
                print(f"üìπ Premi√®re iframe: {first_src}")
                return first_src
        
        print("‚ùå Aucune iframe trouv√©e")
        return ""
        
    except Exception as e:
        print(f"‚ùå Erreur extraction iframe: {e}")
        return ""

async def extract_anime_sama(
    site_or_url: str,
    keyword: str,
    *,
    episode: Optional[int] = None,
    headless: bool = True,
    timeout_ms: int = 15000,
    use_ddg_backup: bool = True,
    direct_url: Optional[str] = None,  # NEW: passer une URL directe si on l'a
) -> Dict:
    """
    Extrait les informations d'un anime depuis anime-sama.fr
    
    Args:
        site_or_url: URL du site ou nom de domaine
        keyword: Mot-cl√© de recherche
        episode: Num√©ro d'√©pisode √† s√©lectionner
        headless: Mode navigateur invisible
        timeout_ms: Timeout en millisecondes
        use_ddg_backup: Utiliser DuckDuckGo en fallback
        direct_url: URL directe vers la page de l'anime (skip recherche)
    
    Returns:
        Dict avec les r√©sultats de l'extraction
    """
    start = _normalize_site(site_or_url)
    domain = urllib.parse.urlsplit(start).netloc

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=headless,
            args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-blink-features=AutomationControlled"],
        )
        context = await browser.new_context(
            locale="fr-FR",
            user_agent=("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/124.0.0.0 Safari/537.36"),
            viewport={"width": 1366, "height": 768},
            ignore_https_errors=True,
        )
        page = await context.new_page()

        # 0) NEW: si on nous donne d√©j√† l'URL de la fiche ‚Üí on saute la recherche
        if direct_url:
            first = direct_url
            print(f"üéØ URL directe fournie: {direct_url}")
        else:
            # 1) home
            print(f"üè† Acc√®s √† la page d'accueil: {start}")
            await page.goto(start, wait_until="domcontentloaded", timeout=timeout_ms)
            
            # 2) search interne
            used_internal = await _type_search_or_fallback(page, start, keyword, timeout_ms)
            first = await _pick_first_result(page, timeout_ms)
            
            # 2bis) fallback DDG site:
            if not first and use_ddg_backup:
                print("üîÑ Fallback DuckDuckGo...")
                ext = ddg_first_result_site(domain, keyword)
                if ext:
                    first = ext
            
            if not first:
                await context.close()
                await browser.close()
                return {"matched": False, "why": "Aucun r√©sultat", "page_url": page.url}

        # 3) ouvrir la page s√©rie / saison (directe ou trouv√©e)
        print(f"üìñ Ouverture de la page: {first}")
        await page.goto(first, wait_until="domcontentloaded", timeout=timeout_ms)

        # 4) EPISODE + LECTEUR
        ep_sel, lecteur_sel = await _episode_dropdown_locators(page)
        chosen_episode_label = await _select_episode(page, ep_sel, episode)
        lecteur_label, raw_iframe = await _try_each_player_until_sibnet(page, lecteur_sel)

        # 5) build final link
        if _is_sibnet(raw_iframe):
            final_url = _to_sibnet_share(raw_iframe)
            why = "sibnet d√©tect√© ‚Üí lien partage normalis√©"
            matched = True
        else:
            final_url = raw_iframe or ""
            why = "sibnet absent ‚Üí lien du 1er lecteur"
            matched = bool(final_url)

        title = await page.title()
        await context.close()
        await browser.close()

        return {
            "matched": matched,
            "page_url": first,
            "titre": title or "",
            "episode_selected": chosen_episode_label,
            "lecteur_label": lecteur_label,
            "raw_iframe": raw_iframe,
            "final_url": final_url,
            "why": why + ("" if direct_url else " (recherche)"),
        }