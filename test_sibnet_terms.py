#!/usr/bin/env python3

import requests
from bs4 import BeautifulSoup
import re

def test_sibnet_various_terms():
    """Tester diff√©rents termes de recherche sur Sibnet"""
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    }
    
    # Diff√©rents termes √† tester
    search_terms = [
        "anime",
        "–º—É–ª—å—Ç—Ñ–∏–ª—å–º",  # anime en russe
        "–≤–∏–¥–µ–æ",       # vid√©o en russe
        "—Ñ–∏–ª—å–º",       # film en russe
        "–ù–ê–†–£–¢–û",      # Naruto en cyrillique
        "Dragon Ball",
        "–º—É–ª—å—Ç–∏–∫"      # dessin anim√©
    ]
    
    print("üîç TEST DIFF√âRENTS TERMES SIBNET")
    print("=" * 50)
    
    for term in search_terms:
        print(f"\nüìù Recherche: '{term}'")
        
        try:
            # Utiliser le formulaire /search.php avec les bons param√®tres
            search_params = {
                "text": term,
                "inname": "1",
                "intext": "1", 
                "inkeyw": "1",
                "inalbom": "0"
            }
            
            resp = requests.get("https://video.sibnet.ru/search.php", 
                              params=search_params, headers=headers, timeout=15)
            
            print(f"  Status: {resp.status_code}, Taille: {len(resp.text)} chars")
            
            if resp.status_code == 200:
                soup = BeautifulSoup(resp.text, "lxml")
                
                # Chercher le terme dans les r√©sultats
                page_text = soup.get_text().lower()
                if term.lower() in page_text:
                    print(f"  ‚úÖ '{term}' trouv√© dans les r√©sultats")
                    
                    # Compter les liens vid√©o
                    video_links = []
                    for a in soup.find_all("a", href=True):
                        href = a.get("href")
                        if href and re.search(r"/video\d+", href):
                            video_links.append(href)
                    
                    print(f"  üìπ Liens vid√©o: {len(video_links)}")
                    
                    # Afficher les premiers liens
                    for i, link in enumerate(video_links[:3]):
                        if link.startswith("/"):
                            full_link = f"https://video.sibnet.ru{link}"
                        else:
                            full_link = link
                        print(f"    {i+1}. {full_link}")
                        
                    # Si c'est le premier terme qui marche, sauvegarder
                    if video_links and term == search_terms[0]:
                        with open(f"sibnet_results_{term}.html", "w", encoding="utf-8") as f:
                            f.write(resp.text)
                        print(f"  üìÑ R√©sultats sauvegard√©s")
                        
                else:
                    print(f"  ‚ùå '{term}' PAS trouv√© dans les r√©sultats")
                    
        except Exception as e:
            print(f"  ‚ùå Erreur: {e}")
    
    # Test sp√©cial: regarder la structure de la page de r√©sultats
    print(f"\nüî¨ ANALYSE STRUCTURE PAGE R√âSULTATS")
    try:
        resp = requests.get("https://video.sibnet.ru/search.php", 
                          params={"text": "anime", "inname": "1", "intext": "1", "inkeyw": "1"}, 
                          headers=headers, timeout=15)
        
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, "lxml")
            
            # Chercher diff√©rents types de conteneurs
            containers = [
                (".result", "result"),
                (".video", "video"), 
                (".item", "item"),
                ("tr", "table row"),
                ("div[class*='video']", "video div"),
                ("td", "table cell")
            ]
            
            for selector, name in containers:
                elements = soup.select(selector)
                if elements:
                    print(f"  üì¶ {name}: {len(elements)} √©l√©ments")
                    
                    # Examiner le premier √©l√©ment
                    first = elements[0]
                    links = first.find_all("a", href=True)
                    video_links_in_first = [a.get("href") for a in links if a.get("href") and "/video" in a.get("href")]
                    
                    if video_links_in_first:
                        print(f"     Premier √©l√©ment contient {len(video_links_in_first)} lien(s) vid√©o")
                        print(f"     Exemple: {video_links_in_first[0]}")
                        
    except Exception as e:
        print(f"‚ùå Erreur analyse structure: {e}")

if __name__ == "__main__":
    test_sibnet_various_terms()